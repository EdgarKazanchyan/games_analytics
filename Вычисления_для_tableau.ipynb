{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Вычисления_для_tableau.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"7RoIDqi084Vr"},"source":["# Скрипт для расчёта различных метрик с целью дальнейшего использования для создания дашбордов в tableau. Также часть функций можно использовать и для периодической работы с данными"]},{"cell_type":"code","metadata":{"id":"LIKPHNZP09gJ"},"source":["from scipy import integrate, interpolate, optimize\n","import scipy.stats as sps\n","import pandas as pd\n","import numpy as np\n","from math import floor\n","from ast import literal_eval #работает, как eval, но более безопасно\n","from scipy.stats import iqr\n","from datetime import timedelta, date\n","import scipy\n","import datetime\n","import warnings\n","warnings.simplefilter('ignore')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lyfHBX2dBcej","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d7097bb2-3110-412c-9d38-0db2d810811e"},"source":["print(f'версия pandas: {pd.__version__}')\n","print(f'версия numpy: {np.__version__}')\n","print(f'версия scipy: {scipy.__version__}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["версия pandas: 1.1.5\n","версия numpy: 1.19.4\n","версия scipy: 1.4.1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-rFtVLldssZo"},"source":["#Основные функции"]},{"cell_type":"markdown","metadata":{"id":"l8aADh4TpUYq"},"source":["##Функции преобразования и корректировки данных"]},{"cell_type":"code","metadata":{"id":"JpfcLg-a1N--"},"source":["def validation_before_transform(data):\n","  \n","  \"\"\"Служит для проверки данных на значения NaN. Удаляет строки, \n","  содержащие больше одного NaN (одно NaN может соответствовать полю event_value_in_usd).\n","  Возвращает исправленный датафрейм.\n","  \"\"\"\n","\n","  # print(data_for_validate.dtypes)\n","  # print()\n","  data_for_validate = data.copy(deep=True)\n","  null_info = data_for_validate.isnull().sum(axis=1)\n","  # print('строки, содержащие больше 1 NaN', null_info[null_info > 1], sep='\\n')\n","  null_containing_row = null_info[null_info > 2].index\n","  data_for_validate.drop(null_containing_row, axis=0, inplace=True)\n","  data_for_validate.reset_index(drop=True, inplace=True)\n","  return data_for_validate"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0llIMxkS_kUx"},"source":["def transform_data_expand(data):\n","\n","  '''На вход получает уже проверенные данные (т.е. после проверки данных на validation_before_transform). \n","  Это расширенное преобразование данных (включая поле event_timstamp), \n","  а именно: изменение типа полей с датами. Возвращает  транформированный датафрейм.'''\n","\n","  data_copy = data.copy(deep=True)\n","  # корректируем тип данных в event_timestamp и event_date (делаем тип datetime)\n","  data_copy.event_timestamp = pd.to_datetime(data_copy.event_timestamp)\n","  data_copy.event_date = pd.to_datetime(data_copy.event_date)\n","  data_copy.event_date = data_copy.event_date.dt.date\n","\n","  # создаём поле с user_first_open (учитываем также, что first_open_time исходно может быть дан в микросекундах и переводим в миллисекунды)\n","  data_copy.first_open_time = data_copy.first_open_time.apply(lambda x: x / 1000 if (x > 10**14) else x)\n","  data_copy.first_open_time = pd.to_datetime(data_copy.first_open_time, unit='ms')\n","  data_copy['cohort'] = data_copy.first_open_time.dt.date\n","\n","  #сортируем данные по полям cohort_date, event_date\n","  data_copy.sort_values(['event_date'], ascending=[True], inplace=True)\n","  data_copy = data_copy.reset_index(drop=True)\n","  data_copy = data_copy.loc[:, ['event_name', 'event_date', 'event_timestamp', 'event_value_in_usd', 'user_pseudo_id', 'game', 'cohort', 'first_open_time', 'product_id']]\n","  data_copy = data_copy.sort_values(by=['cohort', 'event_date'], ascending=[True, True])\n","  return data_copy"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VsQb6hjxOlU3"},"source":["def date_corrector(data):\n","\n","  \"\"\"Корректирует дату в поле cohort (по наиболее частотному), или же удаляет, если такая некорректная дата одна в датафрейме. Нужен, чтобы\n","  в датафрейме не появлялись аномальные значения. Получает данные, вышедшие из transform_data\"\"\"\n","\n","  # формируем список пользователей, у которых есть хотя бы одно некорректное значение в cohort_date\n","  users_inc = set(data[data.cohort < pd.to_datetime('2019-01-01')].user_pseudo_id)\n","  for user_id in users_inc:\n","    # берём индексы всех строк с пользователем user_id, у которого некорректное cohort_date \n","    indexes_of_user = list(data.query(\"user_pseudo_id == @user_id\").index) \n","    if len(indexes_of_user) == 1:\n","      data.drop(indexes_of_user, axis=0, inplace=True)\n","    else:\n","      # находим корректную дату cohort_date для данного user_id, как наиболее часто встречающуюся для данного пользователя\n","      correct_date = data.cohort[indexes_of_user].value_counts().idxmax()\n","      if correct_date < pd.to_datetime('2019-01-01'):\n","        data.drop(indexes_of_user, axis=0, inplace=True)\n","      else:\n","         # установка для пользователя user_id корректной cohort_date\n","        data.cohort[indexes_of_user] = correct_date\n","  data = data.sort_values(by=['cohort', 'event_date'], ascending=[True, True]).reset_index(drop=True)\n","  return data"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TeHyYPiepa8Y"},"source":["##Функции для вычислений"]},{"cell_type":"markdown","metadata":{"id":"h--GvcZbUSfy"},"source":["###Для расчёта метрик (LTV, LT, Retention и т.д.)"]},{"cell_type":"code","metadata":{"id":"0WH1EYDqkQAi"},"source":["def paying_share_calc(data):\n","\n","  \"\"\"Для вычисления paying share. Возвращает медианный ДНЕВНОЙ paying share\n","     (т.е. вычисляет дневной paying share для каждой даты а затем берёт медиану). \n","     На вход принимает трансформированные данные.\"\"\"\n","\n","  purchase_u = data.query(\"event_name=='in_app_purchase'\")\\\n","                        .groupby('event_date', as_index=False).agg({'user_pseudo_id': 'nunique'})\\\n","                        .rename(columns={'user_pseudo_id': 'purchase_users'})\n","  all_u = data.groupby('event_date', as_index=False).agg({'user_pseudo_id': 'nunique'})\\\n","                   .rename(columns={'user_pseudo_id': 'all_users'})\n","  all_info = purchase_u.merge(all_u, on='event_date')\n","  ps = round(all_info.purchase_users / all_info.all_users * 100, 1)\n","  return ps.median()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7t-8X__et4hc"},"source":["def purchase_users_data(data, purchase=True, paying_share_return=False):\n","\n","  \"\"\"Формирует датасет только с пользователями, у которых есть хотя бы один платёж (purchase_users) \n","  и только с теми, у которых нет ни одного платежа (unpurchase_users). \n","  На вход получает трансформированные данные.\n","\n","  Parameters:\n","  ----------\n","  data: dataframe\n","    Датафрейм, вышедший из функции transform_data_expand\n","  purchase: bool\n","    Данный параметр позволяет выбрать, датафрейм с данными каких игроков\n","    мы получим на выходе из этой функции: purchase=True означает выбрать \n","    платящих, а False - неплатящих.\n","  paying_share_return: bool\n","    Если paying_share_return==True, то функция возвращает долю платящих \n","    игроков paying_share за весь период, за который получены данные.\n","\n","  Returns:\n","  -------\n","  В зависимости от настроек параметров \n","  возваращает либо датафрейм с информацией о платящих \n","  или неплатящих игроках либо paying share за весь период данных.\n","  \"\"\"\n","  purchase_users_set = set(data.query(\"event_name == 'in_app_purchase'\").user_pseudo_id) # множество всех платящих пользователей\n","  all_users_set = set(data.user_pseudo_id)# множество всех пользователей\n","  unpurchase_users_set = all_users_set.difference(purchase_users_set)# множество всех неплатящих пользователей\n","  purchase_users = data.query(\"user_pseudo_id in @purchase_users_set\").reset_index(drop=True) # датафрейм со всеми событиями для платящих пользователей\n","  unpurchase_users = data.query(\"user_pseudo_id in @unpurchase_users_set\").reset_index(drop=True)# датафрейм со всеми событиями для неплатящих пользователей\n","  paying_share = len(purchase_users_set) / len(all_users_set)\n","  if paying_share_return:\n","    return paying_share\n","  else:\n","    if purchase: \n","      return purchase_users\n","    else:\n","      return unpurchase_users "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hcrTwAb_31Y_"},"source":["def pivot_table_for_ltv(data, users='all'):\n","\n","  '''Для вычисления retention, arpu, arppu (т.е. для всего, что нужно, что вычислить LTV). \n","  Возвращает датафрейм, содержащий значение retention на каждый день для каждой когорты.\n","  \n","  Paramters: \n","  ---------\n","  data: dataframe\n","    Обычные трансформированные данные\n","  users: str, in ['all', 'purchase']\n","    Позволяет выбрать, для каких игроков (платящих или неплатящих)\n","    необходимо выполнять расчёты (всех или только платящих)\n","  \n","  Returns:\n","  -------\n","  all_data: dataframe\n","    Датафрейм со всей необходимой информацией для дальнейшего\n","    расчёта retention, arpu, arppu, LTV, liftime.\n","    '''\n","\n","  if users == 'all':\n","    users_data = data\n","    metrics = 'arpu'\n","  elif users == 'purchase':\n","    users_data = purchase_users_data(data)\n","    metrics = 'arppu'\n","\n","  # группируем данные для ретеншн\n","  all_data = users_data.groupby(['event_date', 'cohort'], as_index=False)\\\n","  .agg({'user_pseudo_id': 'nunique'})\\\n","  .sort_values(by=['event_date', 'cohort'])\\\n","  .rename(columns={'user_pseudo_id': 'retention'}) \n","\n","  # находит уникальных юзеров для каждой когорты\n","  cohort_unique_users = users_data.groupby('cohort', as_index=False)\\\n","  .agg({'user_pseudo_id': 'nunique'})\\\n","  .rename(columns={'user_pseudo_id': 'unique_users_at_cohort'}) \n","\n","  # находит уникальных юзеров и revenue для каждого дня\n","  date_info = users_data.groupby('event_date', as_index=False)\\\n","  .agg({'user_pseudo_id': 'nunique', 'event_value_in_usd': 'sum'})\\\n","  .rename(columns={'user_pseudo_id': 'unique_users_at_date', 'event_value_in_usd': 'revenue_at_date'}) \n","\n","  # найдём arpu (arppu)\n","  metrics_data = date_info.revenue_at_date / date_info.unique_users_at_date\n","  date_info_and_metrics = pd.concat([date_info, metrics_data], axis=1)\\\n","  .rename(columns={0: metrics})\n","  \n","  # добавим поле, указывающее для каждой когорты число уникальных юзеров\n","  all_data = all_data.merge(cohort_unique_users, on='cohort') \n","  # добавим ретеншн в долях\n","  all_data['retention_fract'] = all_data.retention / all_data.unique_users_at_cohort \n","\n","  all_data = all_data.merge(date_info_and_metrics, on='event_date')\n","\n","  return all_data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jk-SZjm8eOIg"},"source":["def arpu_arppu_calc(data, users='all', period=None):\n","\n","  \"\"\"Вычисляет arpu/arppu (по умолчанию среднее ДНЕВНОЕ arpu (arppu), используя все данные из data).\n","    Если users = 'all', то вычисляется arpu (т.к. будет учитываться все игрок).\n","    Если users='purchase', вычисляетя arppu. Если задан period (число int), \n","    то будет метрикка будет вычислена за этот period (считая от начальной даты в event_date).\n","    Принимает обычные трансформированные данные\"\"\"\n","\n","  #вычислим arpu/arppu за период period\n","  if period is not None:\n","    first_date = data.event_date.min()\n","    finish_date = first_date + timedelta(days=period)\n","    data = data.query(\"@first_date <= event_date < @finish_date\")\n","    if users == 'all':\n","      metrics = 'arpu'\n","      arpu_arppu = data.event_value_in_usd.sum() / data.user_pseudo_id.nunique()\n","    else:\n","      metrics = 'arppu'\n","      data = purchase_users_data(data)\n","      arpu_arppu = data.event_value_in_usd.sum() / data.user_pseudo_id.nunique()\n","    return arpu_arppu\n","    \n","  # вычислим среднее дневное arpu/arppu \n","  if users == 'all':\n","    metrics = 'arpu'\n","    data_for_calc_arpu_arppu = data.groupby('event_date', as_index=False)\\\n","                                   .agg({'event_value_in_usd': 'sum', 'user_pseudo_id': 'nunique'})\n","  else:\n","    metrics = 'arppu'\n","    data_for_calc_arpu_arppu = purchase_users_data(data).groupby('event_date', as_index=False)\\\n","                                                       .agg({'event_value_in_usd': 'sum', 'user_pseudo_id': 'nunique'})\n","  average_arpu_arppu = (data_for_calc_arpu_arppu.event_value_in_usd / data_for_calc_arpu_arppu.user_pseudo_id).mean()\n","  return average_arpu_arppu"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1XBopQ0qU3kp"},"source":["def weekly_metrics_calc(data):\n","\n","  \"\"\"Расчёт недельных значений метрик для конкретной игры. \n","  Принимает на вход трансформированные данные для конкретной игры.\n","  Возвращает кортеж из значениий НЕДЕЛЬНЫХ метрик: \n","  Paying share, WAU, ARPU, ARPPU, New users для данной игры за первую неделю. \n","  first_purchase_interval вычисляется в днях.\n","  \n","  Parameters:\n","  -----------\n","  data: dataframe\n","    Датафрейм с недельными данными для одной игры, \n","    выгруженный из базы данных.\n","  \n","  Retruns:\n","  -------\n","  Кортеж вида (paying_share, wau, arpu, arppu, number_of_new_users, first_purchase_interval, new_users_paying_share)\n","  \"\"\"\n","\n","  #выберем датасет с данными за неделю\n","  start_date = data.event_date.min()\n","  finish_date = start_date + timedelta(days=7)\n","  data_for_week = data.query(\"@start_date <= event_date < @finish_date\")\n","  \n","  #промаркируем пользователей, как новых (первое появление было в этих данных data (не путать с data_need))\n","  # и старых (первое появление было раньше, чем минимальный event_date в наших данных)\n","  data_for_week['new_or_old'] = 0\n","  data_for_week.loc[data_for_week.cohort < start_date, ['new_or_old']] = 'old'\n","  data_for_week.loc[data_for_week.cohort >= start_date, ['new_or_old']] = 'new'\n","  data_for_week.reset_index(drop=True, inplace=True)\n","\n","  # вычислим метрики\n","  paying_share = round(purchase_users_data(data_for_week, paying_share_return=True) * 100, 1)\n","  wau = data_for_week.user_pseudo_id.nunique()\n","  arpu = round(data_for_week.event_value_in_usd.sum() / wau, 2)\n","  arppu = round(arpu / paying_share * 100, 1)\n","  number_of_new_users = data_for_week.query(\"@start_date <= cohort < @finish_date\").user_pseudo_id.nunique()\n","  first_purchase_interval = round(users_all_info(data_for_week).query(\"new_or_old == 'new'\").interval.median(), 2)\n","  new_users_paying_share = round(purchase_users_data(data_for_week.query(\"new_or_old == 'new'\"), paying_share_return=True) * 100, 1)\n","  return (paying_share, wau, arpu, arppu, number_of_new_users, first_purchase_interval, new_users_paying_share)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EMPF9WY1hhoy"},"source":["def games_metrics(data):\n","\n","  \"\"\"Полный аналог weekly_metrics_calc, только \n","     позволяет вычислить значения метрик для множества игр (а не только для одной).\n","     Возвращает датафрейм со значением каждой из метрик для каждой из игр за ПЕРВУЮ неделю.\n","     \n","    Paramters:\n","    ----------\n","    data: dataframe\n","      Датафрейм с данными по множеству игр за одну неделю.\n","    \n","    Returns:\n","    -------\n","      Датафрейм со значениями недельных метрик для множества игр.\n","     \"\"\"\n","\n","  game_list = list(data.game.unique())\n","  game_name = game_list[0]\n","  metrics_list = ['Paying share', 'WAU', 'ARPU', 'ARPPU', 'New users',\n","                  'First purchase time interval', 'New_users_paying_share']\n","  game_data = data.query(\"game == @game_name\")\n","  metrics = weekly_metrics_calc(game_data)\n","  result_frame = pd.DataFrame({'Игра': [game_name, game_name, game_name,game_name, game_name, game_name, game_name], 'Название метрики': metrics_list, 'Неделя 1': metrics})\n","  \n","  # для каждой игры из списка game_list (кроме первой, она уже учтена выше) создадим датафрейм\n","  for i in range(1, len(game_list)):\n","    game_name = game_list[i]\n","    game_data = data.query(\"game == @game_name\")\n","    metrics = weekly_metrics_calc(game_data)\n","    \n","    # создадим датафрейм, содержащий значения всех метрик для данной игры\n","    game_frame = pd.DataFrame({'Игра': [game_name, game_name, game_name,game_name, game_name, game_name, game_name], 'Название метрики': metrics_list, 'Неделя 1': metrics})\n","    #объединим датафрейм с метриками для данной игры с \n","    #датафреймом, содержащим метрики для остальных игр, чтобы у нас был единый датайрейм с метриками для всех игр\n","    result_frame = pd.concat([result_frame, game_frame])\n","  return result_frame"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Y_7AE3STUA-z"},"source":["###Для работы со сводной пользовательской информацией для ПЛАТЯЩИХ пользователей (users info)"]},{"cell_type":"code","metadata":{"id":"80NfnU59pk54"},"source":["def users_all_info(data):\n","\n","  \"\"\"Создаёт сводную таблицу по ПЛАТЯЩИМ игрокам со множеством полей для каждого игрока \n","  (суммарный платёж, дата первого платежа, количество транзакций, тип первой покупки, интервал между первым запуском и первым платежом).\n","  Т.е. в данной таблице для каждого игрока присутствует преимущественно информация о его первой покупке.\n","  На вход получает трансформированные данные\"\"\"\n","  \n","  data_need = purchase_users_data(data).query(\"event_name == 'in_app_purchase'\").sort_values(by='event_timestamp')\n","  # найдём первую покупку для каждого пользователя\n","  first_purchase_each_users = data_need\\\n","  .groupby('user_pseudo_id', as_index=False).first()[['user_pseudo_id', 'event_date', 'event_timestamp',\n","                                                      'product_id', 'event_value_in_usd', 'first_open_time', 'new_or_old']]\\\n","                                            .rename(columns={'event_timestamp': 'first_purchase_date', 'event_value_in_usd': 'first_purchase_in_usd',\n","                                                             'user_pseudo_id': 'user_id', 'first_open_time': 'first_run_date'})\n","  \n","  # придадим полю product_id более сносный вид (т.е. оставим для каждого значения только соответствующий iap)\n","  first_purchase_each_users.product_id = first_purchase_each_users.product_id.apply(lambda x: x.split('.')[-1])\n","  summ_revenue_each_users = data_need.groupby('user_pseudo_id', as_index=False)\\\n","  .agg({'event_value_in_usd': 'sum'}).rename(columns={'event_value_in_usd': 'summ_revenue_in_usd'})\n","\n","  count_purchase_each_users = data_need.query(\"event_name == 'in_app_purchase'\")\\\n","  .groupby('user_pseudo_id', as_index=False).agg({'event_value_in_usd': 'count'}).rename(columns={'event_value_in_usd': 'number_of_transactions'})\n","\n","  data_users_info = pd.concat([first_purchase_each_users, summ_revenue_each_users, count_purchase_each_users], axis=1).drop(columns=['user_pseudo_id'])\n","  data_users_info['interval'] = round((data_users_info.first_purchase_date - data_users_info.first_run_date).dt.total_seconds() / 86400, 2)\n","  return data_users_info"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4ejCtZNfTeWb"},"source":["def users_ejection_free_info(data):\n","\n","  \"\"\"Возвращает данные о пользователях (то же, что и users_all_info), \n","    в которых удалены выбросы.\n","    На вход получает данные от функции users_all_info\n","    Parameters:\n","      data: dataframe\n","    Returns:\n","      Кортеж из dataframe с очищенной от выбросов информацией \n","      о пользователях и долей оставшихся после удаления пользователей\"\"\"\n","\n","  users_info = data.copy(deep=True)\n","\n","  \"\"\"Находим 'усы' для признаков summ_revenue_in_usd, first_purchase_in_usd\"\"\"\n","  upper_fence_summ = np.quantile(users_info.summ_revenue_in_usd, [0.75]) + 1.5 * iqr(users_info.summ_revenue_in_usd) \n","  lower_fence_summ = np.quantile(users_info.summ_revenue_in_usd, [0.25]) - 1.5 * iqr(users_info.summ_revenue_in_usd)\n","\n","  upper_fence_first = np.quantile(users_info.first_purchase_in_usd, [0.75]) + 1.5 * iqr(users_info.first_purchase_in_usd) \n","  lower_fence_first = np.quantile(users_info.first_purchase_in_usd, [0.25]) - 1.5 * iqr(users_info.first_purchase_in_usd) \n","\n","  users_info = users_info\\\n","  .query(\"@lower_fence_summ < summ_revenue_in_usd < @upper_fence_summ and @lower_fence_first < first_purchase_in_usd < @upper_fence_first\")\n","\n","  \"\"\"Найдём долю пользователей, которых мы оставили\"\"\"\n","  number_ejection = users_info.shape[0] / data.shape[0] * 100\n","  return (users_info, number_ejection)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r4D2id6iYcQe"},"source":["### Функции для расчёта понедельных метрик по уже скачанным играм"]},{"cell_type":"markdown","metadata":{"id":"qDsOln-wgDNQ"},"source":["При добавлении новой метрики нужно делать сделующие поправки:\n","* 1)weekly_metrics: добавить метрику в \"вычислим метрики\" и в return\n","* 2)games_metrics: в metrics_list добавить название метрики. В result_frame и game_frame добавить ещё один game_name (их должно быть по числу метрик).\n","* 3) В normal_view в n=week*число, число увеличить на 1. Также в metrics_names добавить название новой метрики"]},{"cell_type":"code","metadata":{"id":"T0rHCRuHrZdb"},"source":["def first_weekday(date_ser):\n","\n","  \"\"\"Для дат из серии date_ser возвращает первую дату, являющуюся понедельником.\"\"\"\n","\n","  date_ser = date_ser.sort_values()\n","  for i in date_ser:\n","    if i.isoweekday() == 1:\n","      start_date = i\n","      return start_date"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d5mlDhTNvITc"},"source":["def week_metrics(data):\n","\n","  \"\"\"Вычисляет для данных из data (использует поле event_date) даты всех понедельников, \n","  а также номера недель, соответствующих этим понедельникам.\n","\n","  Parameters:\n","  ----------\n","  data: dataframe\n","    Трансформированные или любые другие данные, имеющие поле event_date.\n","  Returns:\n","  -------- \n","    Возвращает кортеж из 2-ух элементов: \n","    списка с понедельниками и списка с номерами недель, соответствующих этим понедельникам.\"\"\"\n","\n","  # найдём начальную и конечную даты, между которыми будут располагаться наши понедельники\n","  start_dat = first_weekday(data.event_date)\n","  end_dat = data.event_date.max()\n","\n","  # создадим список из понедельников и список из номеров недель\n","  date_periods = pd.date_range(start=start_dat, freq='7D', end=end_dat)\n","  week_number_list = [i.isocalendar()[1] for i in date_periods]\n","  return (date_periods, week_number_list)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DrHezLrU3jfE"},"source":["def main_week_metrics(users_data, platform=None):\n","\n","  \"\"\"Возвращает датафрейм с вычисленными метриками для каждой недели для одной игры. \n","  users_data - любые данные (трансформированные, или по сегментам) о СОБЫТИЯХ, а не просто о пользователях для ОДНОЙ ИГРЫ.\n","  platform нужен, чтобы в датафрейме дополнительно указать информацию о платформе (ios, android).\"\"\"\n","\n","  #получим начальные и конечные даты периода, для которого будем вычислять метрики\n","  start = week_metrics(users_data)[0][0]\n","  finish = week_metrics(users_data)[0][1]\n","  #получим номер недели\n","  week_n = week_metrics(users_data)[1][0]\n","  data = users_data.query(\"@start <= event_date < @finish\")\n","  #вычислим метрики\n","  metr = games_metrics(data)\n","  metr = metr.merge(metr[['Название метрики', 'Неделя 1']], on='Название метрики').rename(columns={'Неделя 1_y': f'{week_n}'})\n","  # пробежимся по каждой неделе и для каждой недели вычислим значения основных метрик (как выше в функции)\n","  for i in range(1, len(week_metrics(users_data)[0]) - 1):\n","    start = week_metrics(users_data)[0][i]\n","    finish = week_metrics(users_data)[0][i+1]\n","    week_n = week_metrics(users_data)[1][i]\n","    data = users_data.query(\"@start <= event_date < @finish\")\n","    for_append = games_metrics(data)\n","    metr = metr.merge(for_append[['Название метрики', 'Неделя 1']], on='Название метрики').rename(columns={'Неделя 1': f'{week_n}'})\n","  metr.drop(columns=['Неделя 1_x'], inplace=True)\n","  if platform is not None:\n","    metr.index = pd.Series([platform, platform, platform, platform, platform])\n","  game_name = metr['Игра'][0].split('.')[2]\n","  metr['Игра'] = game_name\n","  metr.rename(columns={'Игра': 'game_name', 'Название метрики': 'metric_name'}, inplace=True)\n","  return metr\n","  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1ApnPiHfDd5G"},"source":["def normal_view(data, for_a_week=True, platform=None):\n","\n","  \"\"\"Возвращает те же данные, что и main_week_metrics, но в более удобном виде (data должно быть для одной игры).\n","    Если for_a_week ==True, то data должны быть данные за неделю, причём эти данные должны выглядеть \n","    так же, как данные при выходе из main_week_metrics. Если for_a_week ==False, \n","    то передаём обычные трансформированные данные. .\"\"\"\n","\n","  if for_a_week:\n","    metrics_data = data\n","  else:\n","    metrics_data = main_week_metrics(data, platform)\n","  weeks = (len(metrics_data.columns) - 2)\n","  n =  weeks * 7\n","  # построим таблицу нужного размера, чтобы потом  сделать его  датафреймом и заполнить данными\n","  #здесь n = weeks * количество метрик\n","  df = np.zeros((n, 4))\n","  metrics_names = ['Paying share', 'WAU', 'ARPU', 'ARPPU', 'New users', 'First purchase time interval', 'New_users_paying_share']\n","  \n","  #заполним  данные в будущих полях value, week_number (числовые данные)\n","  #пробежимся по каждой метрике, и для каждой метрики загрузим все его значения (по всем неделям) в поле value датафрейма df\n","  # срез i*weeks:(i+1)*weeks имеет длину, равную числу недель, т.е. weeks. \n","  #Он нужен, т.к. у каждой метрики ровно weeks значений, которые и нужно добавить в датафрейм df\n","  for i in range(len(metrics_names)):\n","    df[i*weeks:(i+1)*weeks, 2] = metrics_data.iloc[i, 2::]\n","    df[i*weeks:(i+1)*weeks, 3] = metrics_data.columns[2::]\n","  df = pd.DataFrame(df)\n","  \n","  # заполним  данные в будущих полях metric_name, game_name (строковые данные)\n","  # пробежимся по каждой метрике, и для каждой метрики загрузим его название  \n","  # в поле metric_name датафрейма df. game_name у всех строк одинаковое и берётся из исходного датафрейма metrics_data\n","  for j in range(len(metrics_names)):\n","    df.iloc[j*weeks:(j+1)*weeks, 0] = metrics_names[j]\n","    df.iloc[:, 1] = metrics_data.game_name[0]\n","  if platform is not None:\n","    df['Platform'] = platform\n","  df.rename(columns={0: 'metric_name', 1: 'game_name', 2: 'value', 3: 'week_number'}, inplace=True)\n","  return df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lso275GYczvR"},"source":["def normal_view_week_data(data):\n","  \n","  \"\"\"Используется для получения метрик за первую неделю для множества игр.\n","  data - обычные трансформированные данные по многим играм.\n","  Возвращет нужный для табло датафрейм Внутри себя использует функцию normal_view.\n","  \"\"\"\n","  \n","  #выберим только данные за первую неделю\n","  start_date = first_weekday(data.event_date)\n","  finish_date = start_date + timedelta(days=7)\n","  data = data.query(\"@start_date <= event_date < @finish_date\")\n","  week_n = start_date.isocalendar()[1]\n","\n","  #получим все наши данные с метриками в менее подходящем виде\n","  metrics_data = games_metrics(data)\n","  metrics_data['Игра'] = metrics_data['Игра'].apply(lambda x: x.split('.')[2])\n","  r = metrics_data.rename(columns={'Игра': 'game_name', 'Название метрики': 'metric_name', 'Неделя 1': week_n})\n","  g_list = r.game_name.unique()\n","  \n","  #создадим пустой датафрейм нужного вида для дальнейшего заполнения\n","  result = pd.DataFrame(columns=['metric_name', 'game_name', 'value', 'week_number'])\n","  \n","  #заполним созданный датафрейм\n","  for g in g_list:\n","    game_data = r.query(\"game_name == @g\")\n","    result = result.append(normal_view(game_data))\n","  result['week_number'] = week_n\n","  return result"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lmufb_aQAbFH"},"source":["def main(data, for_a_week=True, platform=None, start_date=None):\n","\n","  \"\"\"Возвращает датафрейм со всеми метриками.\n","  Если for_a_week =True, то data должно быть за неделю.\n","  data - сырые данные.\n","  start_date используется для тестирования с недельными данными (чтобы можно было выставить нужную неделю)\"\"\"\n","  \n","  correct_data = date_corrector(transform_data_expand(data))\n","  if for_a_week:\n","    if start_date is not None:\n","      correct_data = correct_data.query(\"event_date > @start_date\")\n","    result = normal_view_week_data(correct_data)\n","  else:\n","    result = normal_view(correct_data, for_a_week=False, platform=platform)\n","  return result"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hJehx7BO870s"},"source":["####Зависимости в функциях для расчёта недельных метрик для tableau\n","**1)Вызывается фукнция main. Если переданы сырые данные  за 1 неделю для многих игр *(нужно для автоматической обработки недельных данных для tableau)*, то для их обработки будет вызвана функция normal_view_week_data (которая внутри себя применяет normal_view для каждой игры и склеивает полученнные данные). Если же переданы данные за много недель *(нужно для ручной обработки каждой игры)*, но для одной игры, то будет просто использована normal_view.**\n","\n","**2)Функция normal_view получает данные либо за неделю для многих игр, либо за всё время, но для одной игры. Если о многих играх за неделю, то данные должны иметь вид, как при выходе из функции main_week_metrics.При этом normal_view их просто преобразует к нужному виду.** \n","\n","**Если же для одной игры за всё время, то это должны быть обычные трансформированные данные. Дальше эти данные будут переданы функции main_week_metrics, который и вернёт датафрейм с понедельными метриками для данной игры. Начиная с main_week_metrics, все функции работают только с данными для одной игры**\n","\n","**Цель: минимизировать количество функций, чтобы код был более поддерживаемым.**"]}]}
